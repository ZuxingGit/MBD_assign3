{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3b code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_train = pd.read_csv('../data/Groceries data train.csv')\n",
    "df_test = pd.read_csv('../data/Groceries data test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique members in each dataset\n",
    "print(df_train['Member_number'].nunique())  # 3872\n",
    "print(df_test['Member_number'].nunique())  # 3566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check intersection of members between train and test\n",
    "train_members = set(df_train['Member_number'].unique())\n",
    "test_members = set(df_test['Member_number'].unique())\n",
    "intersection = train_members.intersection(test_members)\n",
    "print(\"number of common members: \", len(intersection))  # 3540\n",
    "print(\"Repetition rate: \", len(intersection) / len(train_members))  # 0.9142561983471075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 members in the intersection\n",
    "print(list(intersection)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by member number and create a list of items purchased by each member\n",
    "train_data = df_train.groupby('Member_number')['itemDescription'].apply(set).apply(list).reset_index()\n",
    "test_data = df_test.groupby('Member_number')['itemDescription'].apply(set).apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 members in the train data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 members in the test data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of items purchased by all members in the df_train\n",
    "# show the result in a graph in descending order\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.title(\"Top15 items in Train dataset\")\n",
    "ax = sns.countplot(x='itemDescription', data=df_train, order=df_train['itemDescription'].value_counts().index[:15])\n",
    "\n",
    "# Annotate count number on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of items purchased by all members in the df_test\n",
    "# show the result in a graph in descending order\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.title(\"Top15 items in Test dataset\")\n",
    "ax = sns.countplot(x='itemDescription', data=df_test, order=df_test['itemDescription'].value_counts().index[:15])\n",
    "\n",
    "# Annotate count number on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the transactions by day of the week and count the number of transactions\n",
    "transactions_by_day = df_train.groupby('day_of_week').size()\n",
    "\n",
    "# Plot the number of transactions by day of the week\n",
    "plt.figure(figsize=(10, 6))\n",
    "transactions_by_day.plot(kind='bar')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.title('Transactions(train) Grouped by Day of Week')\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the transactions by day of the week and count the number of transactions\n",
    "transactions_by_day = df_test.groupby('day_of_week').size()\n",
    "\n",
    "# Plot the number of transactions by day of the week\n",
    "plt.figure(figsize=(10, 6))\n",
    "transactions_by_day.plot(kind='bar')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.title('Transactions(test) Grouped by Day of Week')\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show number of items purchased by all members in the train data\n",
    "# x-axis: number of items purchased, y-axis: number of members\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(train_data['itemDescription'].apply(len), bins=50)\n",
    "plt.xticks(range(0, max(train_data['itemDescription'].apply(len)), 1))\n",
    "plt.xlabel('Number of Items Purchased')\n",
    "plt.ylabel('Count of Members')\n",
    "plt.title('Number of Items Purchased by Members in Train Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show number of items purchased by all members in the test data\n",
    "# x-axis: number of items purchased, y-axis: number of members\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(test_data['itemDescription'].apply(len), bins=50)\n",
    "plt.xticks(range(0, max(test_data['itemDescription'].apply(len)), 1))\n",
    "plt.xlabel('Number of Items Purchased')\n",
    "plt.ylabel('Count of Members')\n",
    "plt.title('Number of Items Purchased by Members in Test Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frequent pattern mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick itemsets that has more than 1 item, sort them\n",
    "\n",
    "train_data = train_data['itemDescription'].tolist()\n",
    "train_data = [sorted(list(items)) for items in train_data]\n",
    "train_data = [items for items in train_data if len(items) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_data))\n",
    "for i in range(5):\n",
    "    print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(train_data).transform(train_data)\n",
    "train_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine frequent itemsets\n",
    "freq_items = fpgrowth(train_df, min_support=0.002, use_colnames=True)\n",
    "\n",
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.4)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get range of zhang's metric\n",
    "print(rules['zhangs_metric'].min())\n",
    "print(rules['zhangs_metric'].max())\n",
    "rules.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_items(purchased_items):\n",
    "    # create a list to store the predicted items\n",
    "    predicted_items = []\n",
    "    \n",
    "    # iterate over the top rules\n",
    "    for index, row in rules.iterrows():\n",
    "        # get the items in the antecedent and consequent of the rule\n",
    "        antecedent = row[\"antecedents\"]\n",
    "        consequent = row[\"consequents\"]\n",
    "        \n",
    "        # check if all the items in the antecedent are in the purchased items\n",
    "        if antecedent.issubset(purchased_items):\n",
    "            # add the items in the consequent to the predicted items\n",
    "            for item in consequent:\n",
    "                if item not in purchased_items and item not in predicted_items:\n",
    "                    predicted_items.append(item)\n",
    "    \n",
    "    # return the list of predicted items\n",
    "    return predicted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a sample set of purchased items\n",
    "purchased_items = {'canned beer',\n",
    " 'misc. beverages',\n",
    " 'pastry',\n",
    " 'pickled vegetables',\n",
    " 'sausage',\n",
    " 'soda',\n",
    " 'yogurt'}\n",
    "predicted_items = predict_items(purchased_items)\n",
    "\n",
    "# print the predicted items to the console\n",
    "print(predicted_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique items in the dataset\n",
    "df_train['itemDescription'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the frequency of each item in the dataset, group by Member_number, itemDescription\n",
    "purchase_counts = df_train.groupby(['Member_number', 'itemDescription']).size().reset_index(name='Purchase_Count')\n",
    "\n",
    "# define an empty dataframe to store the results\n",
    "members = df_train['Member_number'].unique()\n",
    "items = df_train['itemDescription'].unique()\n",
    "\n",
    "new_df = pd.DataFrame(index=members, columns=items).fillna(0)\n",
    "\n",
    "# fill the new DataFrame with purchase counts\n",
    "for _, row in purchase_counts.iterrows():\n",
    "    member = row['Member_number']\n",
    "    item = row['itemDescription']\n",
    "    count = row['Purchase_Count']\n",
    "    new_df.at[member, item] = count\n",
    "\n",
    "new_df = new_df.reset_index().rename(columns={'index': 'Member_number'})\n",
    "new_df.set_index('Member_number', inplace=True)\n",
    "new_df = new_df.sort_index()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UV decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# UV decomposition function\n",
    "def uv_decomposition(R, k, learning_rate, regularization):\n",
    "    \"\"\"\n",
    "    Performs UV decomposition on the input matrix R, with a target rank of k, using stochastic gradient descent (SGD).\n",
    "    Returns the decomposed matrices U and V.\n",
    "    \"\"\"\n",
    "    # Initialize U and V with random values\n",
    "    num_users, num_items = R.shape\n",
    "    U = np.random.rand(num_users, k)\n",
    "    V = np.random.rand(k, num_items)\n",
    "\n",
    "    # Perform stochastic gradient descent to optimize U and V\n",
    "    for epoch in range(10):\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_items):\n",
    "                if R[i, j] > 0:\n",
    "                    error = R[i, j] - np.dot(U[i, :], V[:, j])\n",
    "                    U[i, :] += learning_rate * (error * V[:, j] - regularization * U[i, :])\n",
    "                    V[:, j] += learning_rate * (error * U[i, :] - regularization * V[:, j])\n",
    "\n",
    "    # Return the decomposed matrices U and V\n",
    "    return U, V\n",
    "\n",
    "# RMSE calculation function\n",
    "def rmse(R, U, V):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Squared Error (RMSE) between the actual ratings R and the predicted ratings U*V.\n",
    "    \"\"\"\n",
    "    predicted_R = np.dot(U, V)\n",
    "    error = R - predicted_R\n",
    "    error = error[R > 0]  # Only consider known values\n",
    "    return np.sqrt(np.mean(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the purchase counts DataFrame to a numpy array\n",
    "R = new_df.to_numpy()\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "# Perform UV decomposition for different values of k\n",
    "for k in range(1, 8):\n",
    "    U, V = uv_decomposition(R, k, 0.1, 0.1)\n",
    "    error = rmse(R, U, V)\n",
    "    print(f\"k: {k}, RMSE: {error}\")\n",
    "    if error < best_rmse:\n",
    "        best_rmse = error\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k: {best_k}, Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform UV decomposition with the best k value on train data\n",
    "U, V = uv_decomposition(R, best_k, 0.1, 0.1)\n",
    "\n",
    "# Reconstruct the matrix using the decomposed matrices U and V\n",
    "new_df_columns = new_df.columns\n",
    "user_ratings = np.dot(U, V)\n",
    "user_ratings = pd.DataFrame(user_ratings, columns=new_df_columns, index=new_df.index)\n",
    "# discard ratings of items that were already purchased\n",
    "user_ratings = user_ratings.where(R == 0).fillna(0)\n",
    "user_ratings # ratings or interests of each member in each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise ratings to the range of 0-1\n",
    "user_ratings = (user_ratings - user_ratings.min()) / (user_ratings.max() - user_ratings.min())\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top5 recommended items for each member\n",
    "a = []\n",
    "for row in user_ratings.iterrows():\n",
    "    top5 = row[1].sort_values(ascending=False).head(5)\n",
    "    top5_columns = top5.index\n",
    "    b = []\n",
    "    for i in top5.index:\n",
    "        b.append((i, top5[i]))\n",
    "    a.append(b)\n",
    "member_recommendations = pd.DataFrame(a, columns=[\"top_1\", \"top_2\", \"top_3\", \"top_4\", \"top_5\"], index=user_ratings.index)\n",
    "member_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision rate : if one of top 5 recomendation is in test dataset => count += 1\n",
    "itemsets = df_test.groupby(\"Member_number\")[\"itemDescription\"].apply(list).reset_index()\n",
    "# x = set(itemsets.iloc[0, 1])\n",
    "count = 0\n",
    "for i in range(itemsets.shape[0]):\n",
    "  is_in = False\n",
    "  for j in range(5):\n",
    "    if member_recommendations.iloc[i, j][0] in set(itemsets.iloc[i, 1]):\n",
    "      is_in = True\n",
    "  if is_in:\n",
    "    count += 1\n",
    "\n",
    "print(\"precision rate:\")\n",
    "raw_precision = count/itemsets.shape[0]\n",
    "print(raw_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output recomendation use pattern, use predict_items function\n",
    "# # df_origin = pd.read_csv('../data/Groceries data train.csv')\n",
    "\n",
    "# pattern_recommendation = new_df.copy()\n",
    "# pattern_recommendation.drop(pattern_recommendation.columns, axis=1, inplace=True)\n",
    "\n",
    "# # itemsets = df_origin.groupby(\"Member_number\")[\"itemDescription\"].apply(list).reset_index()\n",
    "# item_array = []\n",
    "# for i in range(itemsets.shape[0]):\n",
    "#   current_itemset = itemsets.iloc[i, 1]\n",
    "#   predicted_items = predict_items(current_itemset)\n",
    "#   item_array.append(predicted_items)\n",
    "# pattern_recommendation['recommendation_item'] = item_array\n",
    "# pattern_recommendation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine association results and collaborative filtering ratings to recommend\n",
    "def combine_recommendations(predicted_items, uv_top5):\n",
    "    \"\"\"\n",
    "    if the item is in the top 5 of the UV_top5, then recommend it\n",
    "    if no items are in the top 5 of the UV_top5, then recommend the top 1\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    # sort top5 by its ratings\n",
    "    uv_top5 = dict(sorted(uv_top5.items(), key=lambda x: x[1], reverse=True))\n",
    "    recommendations.append([item for item in uv_top5.keys() if item in predicted_items])\n",
    "    if len(recommendations[0]) == 0:\n",
    "        recommendations[0].append(list(uv_top5.keys())[0])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
